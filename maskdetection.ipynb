{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**  ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoWoNngyTeYU",
    "outputId": "abe456ab-81b9-4213-dbc2-bb92d7007942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "train Loss: 0.1477 Acc: 0.8960\n",
      "val Loss: 0.0924 Acc: 0.9218\n",
      "Epoch 2/50\n",
      "----------\n",
      "train Loss: 0.0747 Acc: 0.9332\n",
      "val Loss: 0.0610 Acc: 0.9371\n",
      "Epoch 3/50\n",
      "----------\n",
      "train Loss: 0.0615 Acc: 0.9451\n",
      "val Loss: 0.0931 Acc: 0.9126\n",
      "Epoch 4/50\n",
      "----------\n",
      "train Loss: 0.0547 Acc: 0.9524\n",
      "val Loss: 0.0864 Acc: 0.9034\n",
      "Epoch 5/50\n",
      "----------\n",
      "train Loss: 0.0514 Acc: 0.9466\n",
      "val Loss: 0.0713 Acc: 0.9141\n",
      "Epoch 6/50\n",
      "----------\n",
      "train Loss: 0.0444 Acc: 0.9570\n",
      "val Loss: 0.0537 Acc: 0.9571\n",
      "Epoch 7/50\n",
      "----------\n",
      "train Loss: 0.0388 Acc: 0.9639\n",
      "val Loss: 0.0600 Acc: 0.9494\n",
      "Epoch 8/50\n",
      "----------\n",
      "train Loss: 0.0229 Acc: 0.9774\n",
      "val Loss: 0.0471 Acc: 0.9632\n",
      "Epoch 9/50\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 0.9877\n",
      "val Loss: 0.0449 Acc: 0.9647\n",
      "Epoch 10/50\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 0.9873\n",
      "val Loss: 0.0458 Acc: 0.9617\n",
      "Epoch 11/50\n",
      "----------\n",
      "train Loss: 0.0100 Acc: 0.9908\n",
      "val Loss: 0.0495 Acc: 0.9663\n",
      "Epoch 12/50\n",
      "----------\n",
      "train Loss: 0.0103 Acc: 0.9885\n",
      "val Loss: 0.0490 Acc: 0.9663\n",
      "Epoch 13/50\n",
      "----------\n",
      "train Loss: 0.0063 Acc: 0.9942\n",
      "val Loss: 0.0434 Acc: 0.9601\n",
      "Epoch 14/50\n",
      "----------\n",
      "train Loss: 0.0051 Acc: 0.9927\n",
      "val Loss: 0.0542 Acc: 0.9586\n",
      "Epoch 15/50\n",
      "----------\n",
      "train Loss: 0.0033 Acc: 0.9962\n",
      "val Loss: 0.0541 Acc: 0.9601\n",
      "Epoch 16/50\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9958\n",
      "val Loss: 0.0557 Acc: 0.9647\n",
      "Epoch 17/50\n",
      "----------\n",
      "train Loss: 0.0046 Acc: 0.9954\n",
      "val Loss: 0.0528 Acc: 0.9663\n",
      "Epoch 18/50\n",
      "----------\n",
      "train Loss: 0.0032 Acc: 0.9992\n",
      "val Loss: 0.0554 Acc: 0.9693\n",
      "Epoch 19/50\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 0.9969\n",
      "val Loss: 0.0572 Acc: 0.9678\n",
      "Epoch 20/50\n",
      "----------\n",
      "train Loss: 0.0030 Acc: 0.9977\n",
      "val Loss: 0.0545 Acc: 0.9647\n",
      "Epoch 21/50\n",
      "----------\n",
      "train Loss: 0.0029 Acc: 0.9981\n",
      "val Loss: 0.0544 Acc: 0.9663\n",
      "Epoch 22/50\n",
      "----------\n",
      "train Loss: 0.0031 Acc: 0.9965\n",
      "val Loss: 0.0535 Acc: 0.9632\n",
      "Epoch 23/50\n",
      "----------\n",
      "train Loss: 0.0027 Acc: 0.9981\n",
      "val Loss: 0.0522 Acc: 0.9647\n",
      "Epoch 24/50\n",
      "----------\n",
      "train Loss: 0.0025 Acc: 0.9981\n",
      "val Loss: 0.0509 Acc: 0.9617\n",
      "Epoch 25/50\n",
      "----------\n",
      "train Loss: 0.0031 Acc: 0.9962\n",
      "val Loss: 0.0547 Acc: 0.9663\n",
      "Epoch 26/50\n",
      "----------\n",
      "train Loss: 0.0024 Acc: 0.9981\n",
      "val Loss: 0.0525 Acc: 0.9632\n",
      "Epoch 27/50\n",
      "----------\n",
      "train Loss: 0.0026 Acc: 0.9977\n",
      "val Loss: 0.0528 Acc: 0.9678\n",
      "Epoch 28/50\n",
      "----------\n",
      "train Loss: 0.0030 Acc: 0.9965\n",
      "val Loss: 0.0548 Acc: 0.9663\n",
      "Early stopping\n",
      "Best val Acc: 0.969325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "NUM_CLASSES = 3\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS =50\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "\n",
    "# Custom Dataset\n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.transform = transform\n",
    "        self.samples = self._load_samples()\n",
    "\n",
    "    def _load_samples(self):\n",
    "        samples = []\n",
    "        for xml_file in os.listdir(self.annotation_dir):\n",
    "            if xml_file.endswith('.xml'):\n",
    "                xml_path = os.path.join(self.annotation_dir, xml_file)\n",
    "                img_path = os.path.join(self.image_dir, xml_file[:-4] + '.png')\n",
    "\n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                objects = root.findall('object')\n",
    "                for obj in objects:\n",
    "                    name = obj.find('name').text\n",
    "                    bbox = obj.find('bndbox')\n",
    "                    xmin = int(bbox.find('xmin').text)\n",
    "                    ymin = int(bbox.find('ymin').text)\n",
    "                    xmax = int(bbox.find('xmax').text)\n",
    "                    ymax = int(bbox.find('ymax').text)\n",
    "\n",
    "                    samples.append((img_path, (xmin, ymin, xmax, ymax), name))\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, bbox, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Crop the image to the bounding box\n",
    "        image = image.crop(bbox)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert label to numeric\n",
    "        label_map = {'with_mask': 0, 'without_mask': 1, 'mask_weared_incorrect': 2}\n",
    "        label = label_map[label]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Model Definition (ResNet18 with modified final layer)\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_wts = model.state_dict()\n",
    "    counter = 0\n",
    "\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_accs.append(epoch_acc)\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_accs.append(epoch_acc)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_val_acc:\n",
    "                best_val_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "                counter = 0\n",
    "            elif phase == 'val':\n",
    "                counter += 1\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print(f'Best val Acc: {best_val_acc:4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "# Inference function\n",
    "def infer(model, image_path, bbox):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.crop(bbox)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    label_map = {0: 'with_mask', 1: 'without_mask', 2: 'mask_weared_incorrect'}\n",
    "    return label_map[preds.item()]\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Set up data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    full_dataset = MaskDataset('/content/drive/MyDrive/c/archive/images', '/content/drive/MyDrive/c/archive/annotations', transform=transform)\n",
    "    train_val_data, test_data = train_test_split(full_dataset, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_val_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Create model and set up training\n",
    "    model = create_model()\n",
    "    criterion = FocalLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # Train model\n",
    "    model, train_losses, train_accs, val_losses, val_accs = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, EARLY_STOPPING_PATIENCE\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'mask_detection_model.pth')\n",
    "\n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # plt.subplot(122)\n",
    "    # plt.plot(train_accs, label='Train')\n",
    "    # plt.plot(val_accs, label='Validation')\n",
    "    # plt.title('Accuracy')\n",
    "    # plt.legend()\n",
    "\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERENCE** ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmQFgG_fkpUe",
    "outputId": "3ef6be34-a41c-495a-f679-d488287456ce"
   },
   "outputs": [],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY2MRRWQlWPi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Constants\n",
    "NUM_CLASSES = 3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model Definition (same as in training script)\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "# Load the trained model\n",
    "def load_model(model_path):\n",
    "    model = create_model()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Preprocess image for inference\n",
    "def preprocess_image(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "# Perform inference on a single face\n",
    "def infer(model, face_image):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(preprocess_image(face_image))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    return preds.item()\n",
    "\n",
    "# Detect faces and perform mask classification\n",
    "def detect_and_classify(image_path, mask_model):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces using RetinaFace through DeepFace\n",
    "    faces = DeepFace.extract_faces(img_path=image_path, detector_backend='retinaface')\n",
    "\n",
    "    # Convert to PIL Image for drawing\n",
    "    pil_image = Image.fromarray(img_rgb)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    # Try to load a font, use default if not available\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    label_map = {0: 'With Mask', 1: 'Without Mask', 2: 'Mask Worn Incorrectly'}\n",
    "    color_map = {0: (0, 255, 0), 1: (255, 0, 0), 2: (255, 255, 0)}  # Green, Red, Yellow\n",
    "\n",
    "    for face in faces:\n",
    "        # Extract face ROI\n",
    "        x = face['facial_area']['x']\n",
    "        y = face['facial_area']['y']\n",
    "        w = face['facial_area']['w']\n",
    "        h = face['facial_area']['h']\n",
    "        face_roi = pil_image.crop((x, y, x+w, y+h))\n",
    "\n",
    "        # Perform inference\n",
    "        prediction = infer(mask_model, face_roi)\n",
    "        label = label_map[prediction]\n",
    "        color = color_map[prediction]\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        draw.rectangle([(x, y), (x+w, y+h)], outline=color, width=2)\n",
    "        draw.text((x, y-25), label, font=font, fill=color)\n",
    "\n",
    "    return pil_image\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    model_path = '/content/drive/MyDrive/c/archive/mask_detection_model.pth'  # Path to your saved model\n",
    "    image_path = '/content/drive/MyDrive/c/archive/images/maksssksksss10.png'  # Path to the test image\n",
    "\n",
    "    # Load the mask detection model\n",
    "    mask_model = load_model(model_path)\n",
    "\n",
    "    # Perform detection and classification\n",
    "    result_image = detect_and_classify(image_path, mask_model)\n",
    "\n",
    "    # Save and show the result\n",
    "    result_image.save('result.jpg')\n",
    "    result_image.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZ1js59IlWL5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
